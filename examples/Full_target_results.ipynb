{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/psnigdha/compare-selection\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from copy import copy\n",
    "import seaborn as sns\n",
    "import hashlib\n",
    "%load_ext rpy2.ipython\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rpy2.robjects as rpy\n",
    "from rpy2.robjects import numpy2ri\n",
    "\n",
    "from traitlets import (Bool,\n",
    "                       Integer,\n",
    "                       Unicode,\n",
    "                       Float,\n",
    "                       Instance)\n",
    "\n",
    "### selectinf imports\n",
    "\n",
    "from selectinf.algorithms.lasso import lasso, ROSI as ROSI_lasso\n",
    "from selectinf.randomized.lasso import lasso as rand_lasso\n",
    "\n",
    "### local imports\n",
    "\n",
    "import sys, os\n",
    "srcdir = os.path.abspath(os.path.join(os.curdir, '..'))\n",
    "print(srcdir)\n",
    "sys.path.insert(0, srcdir)\n",
    "from instances import AR_instance\n",
    "from utils import (gaussian_setup,\n",
    "                   get_method_params)\n",
    "                   \n",
    "from gaussian_methods import (lasso_theory,\n",
    "                              ROSI_theory,\n",
    "                              randomized_lasso) # we will explicitly write out the classes\n",
    "                                                # here, inheriting from ROSI_theory\n",
    "from statistics import interval_statistic, estimator_statistic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch simulation code from `bestsubset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"https://raw.githubusercontent.com/ryantibs/best-subset/master/bestsubset/R/common.R\")\n",
    "source(\"https://raw.githubusercontent.com/ryantibs/best-subset/master/bestsubset/R/sim.R\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def simulate(n=500,\n",
    "             p=100,\n",
    "             nval=500,\n",
    "             s=10,\n",
    "             rho=0.35,\n",
    "             beta_type=1,\n",
    "             snr=0.2):\n",
    "\n",
    "    numpy2ri.activate()\n",
    "    r_simulate = rpy.globalenv['sim.xy']\n",
    "    sim = r_simulate(n, p, nval, rho, s, beta_type, snr)\n",
    "    X = np.array(sim.rx2('x'))\n",
    "    y = np.array(sim.rx2('y'))\n",
    "    \n",
    "    X -= X.mean(0)[None, :]\n",
    "    X /= (X.std(0)[None, :] * np.sqrt(n / (n - 1)))\n",
    "    y = y - y.mean()\n",
    "    \n",
    "    X_val = np.array(sim.rx2('xval'))\n",
    "    y_val = np.array(sim.rx2('yval'))\n",
    "    Sigma = np.array(sim.rx2('Sigma'))\n",
    "    beta = np.array(sim.rx2('beta'))\n",
    "    noise_sd = np.array(sim.rx2('sigma')).reshape(())\n",
    "    numpy2ri.deactivate()\n",
    "    return X, y, Sigma, beta, noise_sd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract $\\lambda$ and point estimate from `glmnet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(glmnet)\n",
    "glmnet_LASSO = function(X, y, lambda){                                            \n",
    "    y = as.numeric(y)                                                                 \n",
    "    X = as.matrix(X)                                                                 \n",
    "    lam = as.matrix(lambda)[1,1]                                                     \n",
    "    n = nrow(X)                                                                      \n",
    "                                                                                                 \n",
    "    fit = glmnet(X, y, standardize=FALSE, intercept=FALSE, thresh=1.e-10)             \n",
    "    estimate.theory = coef(fit, s=lam, exact=TRUE, x=X, y=y)[-1]                            \n",
    "    fit.cv = cv.glmnet(X, y, standardize=FALSE, intercept=FALSE, thresh=1.e-10)       \n",
    "    estimate.1se = coef(fit, s=fit.cv$lambda.1se, exact=TRUE, x=X, y=y)[-1]            \n",
    "    estimate.min = coef(fit, s=fit.cv$lambda.min, exact=TRUE, x=X, y=y)[-1]            \n",
    "    return(list(estimate.theory=estimate.theory, \n",
    "                estimate.1se=estimate.1se, \n",
    "                estimate.min=estimate.min, \n",
    "                lam.min=fit.cv$lambda.min, \n",
    "                lam.1se=fit.cv$lambda.1se))                            \n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glmnet_setup(X, \n",
    "                 y, \n",
    "                 full_dispersion=True):\n",
    "\n",
    "    n, p = X.shape\n",
    "    if full_dispersion:\n",
    "        dispersion = np.linalg.norm(y - X.dot(np.linalg.pinv(X).dot(y))) ** 2 / (n - p)\n",
    "        sigma_ = np.sqrt(dispersion)\n",
    "    else:\n",
    "        dispersion = None\n",
    "        sigma_ = np.std(y)\n",
    "\n",
    "    lam_theory = sigma_ * 1. * np.mean(np.fabs(np.dot(X.T,\n",
    "                        np.random.standard_normal((n,\n",
    "                                                   2000)))).max(0)) / n\n",
    "    \n",
    "    numpy2ri.activate()\n",
    "    lambda_R = rpy.globalenv['glmnet_LASSO']\n",
    "    n, p = X.shape\n",
    "    r_X = rpy.r.matrix(X, nrow=n, ncol=p)\n",
    "    r_y = rpy.r.matrix(y, nrow=n, ncol=1)\n",
    "    r_lam = rpy.r.matrix(lam_theory/float(n), nrow=1, ncol=1)\n",
    "\n",
    "    val = lambda_R(r_X, r_y, r_lam)\n",
    "    estimate_theory = np.array(val.rx2('estimate.theory'))\n",
    "    estimate_1se = np.array(val.rx2('estimate.1se'))\n",
    "    estimate_min = np.array(val.rx2('estimate.min'))\n",
    "    lam_min = np.array(val.rx2('lam.min'))[0]\n",
    "    lam_1se = np.array(val.rx2('lam.1se'))[0]\n",
    "    numpy2ri.deactivate()\n",
    "    return estimate_theory, estimate_1se, estimate_min, lam_theory, lam_1se, lam_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an instance generator from `sim.xy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class best_subset_data(AR_instance):\n",
    "    \n",
    "    instance_name = Unicode('Best Subset (R)')\n",
    "    n = Integer(500)\n",
    "    nval = Integer(500)\n",
    "    p = Integer(100)\n",
    "    s = Integer(20)\n",
    "    rho = Float(0.35)\n",
    "    l_theory = Float()\n",
    "    feature_cov = Instance(np.ndarray)\n",
    "    snr = Float(0.2)\n",
    "    noise = Float(1.)\n",
    "    beta_type = Integer(1)\n",
    "\n",
    "    def generate_X(self):\n",
    "        \n",
    "        X = simulate(n=self.n,\n",
    "                     p=self.p,\n",
    "                     nval=self.nval,\n",
    "                     rho=self.rho,\n",
    "                     s=self.s,\n",
    "                     beta_type=self.beta_type,\n",
    "                     snr=self.snr)[0]\n",
    "\n",
    "        return X\n",
    "\n",
    "    def generate(self):\n",
    "        \n",
    "        (X,\n",
    "         Y,\n",
    "         Sigma,\n",
    "         beta,\n",
    "         noise_sd) = simulate(n=self.n,\n",
    "                              p=self.p,\n",
    "                              nval=self.nval,\n",
    "                              rho=self.rho,\n",
    "                              s=self.s,\n",
    "                              beta_type=self.beta_type,\n",
    "                              snr=self.snr)\n",
    "        self.feature_cov = Sigma \n",
    "        \n",
    "        self._beta = beta\n",
    "        Y = X.dot(self._beta) + noise_sd * np.random.standard_normal(self.n)\n",
    "        return X, Y, self._beta\n",
    "\n",
    "instance = best_subset_data(n=300, p=100, nval=100, s=5, rho=0.35)\n",
    "X, Y = instance.generate()[:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Liu, Markovic and Tibshirani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "class ROSI(ROSI_theory):\n",
    "    \n",
    "    sigma_estimator = Unicode('relaxed')\n",
    "    method_name = Unicode(\"Full (Nonrandom)\")\n",
    "    lambda_choice = Unicode(\"CV\")\n",
    "    model_target = Unicode(\"full\")\n",
    "    dispersion = Float(0.)\n",
    "    approximate_inverse = Unicode('BN')\n",
    "    estimator = Unicode(\"OLS\")\n",
    "\n",
    "    def __init__(self, X, Y, l_theory, l_min, l_1se, sigma_reid):\n",
    "\n",
    "        ROSI_theory.__init__(self, X, Y, l_theory, l_min, l_1se, sigma_reid)\n",
    "        n, p = X.shape\n",
    "        self.lagrange = l_min * np.ones(X.shape[1])\n",
    "\n",
    "    @property\n",
    "    def method_instance(self):\n",
    "        if not hasattr(self, \"_method_instance\"):\n",
    "            n, p = self.X.shape\n",
    "            self._method_instance = ROSI_lasso.gaussian(self.X,\n",
    "                                                        self.Y,\n",
    "                                                        self.lagrange * n,\n",
    "                                                        approximate_inverse=self.approximate_inverse)\n",
    "        return self._method_instance\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Lee et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lee(lasso_theory):\n",
    "    \n",
    "    sigma_estimator = Unicode('relaxed')\n",
    "    method_name = Unicode(\"Nonrandom\")\n",
    "    lambda_choice = Unicode(\"CV\")\n",
    "    model_target = Unicode(\"full\")\n",
    "    estimator = Unicode(\"LASSO\")\n",
    "    \n",
    "    def __init__(self, X, Y, l_theory, l_min, l_1se, sigma_reid):\n",
    "\n",
    "        lasso_theory.__init__(self, X, Y, l_theory, l_min, l_1se, sigma_reid)\n",
    "        n, p = X.shape\n",
    "        self.lagrange = l_min * np.ones(X.shape[1])\n",
    "        self.dispersion = np.linalg.norm(Y - X.dot(np.linalg.pinv(X).dot(Y))) ** 2 / (n - p)\n",
    "        \n",
    "    @property\n",
    "    def method_instance(self):\n",
    "        if not hasattr(self, \"_method_instance\"):\n",
    "            n, p = self.X.shape\n",
    "            self._method_instance = lasso.gaussian(self.X,\n",
    "                                                   self.Y,\n",
    "                                                   self.lagrange * n)\n",
    "        return self._method_instance\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of naive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Naive(Lee):\n",
    "    \n",
    "    method_name = Unicode(\"Naive\")\n",
    "    \n",
    "    def generate_summary(self, compute_intervals=True):\n",
    "        if not self._fit:\n",
    "            self.method_instance.fit()\n",
    "            self._fit = True\n",
    "\n",
    "        X, Y, lagrange, L = self.X, self.Y, self.lagrange, self.method_instance\n",
    "        n, p = X.shape\n",
    "        \n",
    "        if len(L.active) > 0:\n",
    "            S = L.summary(compute_intervals=False)\n",
    "            lower, upper = self.naive_intervals(L.active)[1:3]\n",
    "            pvalue = self.naive_pvalues(L.active)[1]\n",
    "            return pd.DataFrame({'variable':L.active,\n",
    "                                 'upper_confidence':upper,\n",
    "                                 'lower_confidence':lower,\n",
    "                                 'onestep':S['onestep'],\n",
    "                                 'lasso':S['lasso'],\n",
    "                                 'pvalue':pvalue})\n",
    "    \n",
    "    def generate_pvalues(self):\n",
    "        S = self.generate_summary()\n",
    "        if S is not None:\n",
    "            return np.array(S['variable']), np.array(S['pvalue'])\n",
    "        else:\n",
    "            return [], []\n",
    "        \n",
    "    def generate_intervals(self):\n",
    "        S = self.generate_summary()\n",
    "        if S is not None:\n",
    "            return (np.array(S['variable']), \n",
    "                    np.array(S['lower_confidence']), \n",
    "                    np.array(S['upper_confidence']), \n",
    "                    np.array(S['pvalue']))\n",
    "        else:\n",
    "            return [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of randomized LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Randomized(randomized_lasso):\n",
    "\n",
    "    use_MLE = Bool(False)\n",
    "    randomizer_scale = Float(np.sqrt(0.5))\n",
    "    method_name = Unicode(\"Randomized\")\n",
    "    model_target = Unicode(\"full\")\n",
    "    lambda_choice = Unicode('1se')\n",
    "    use_initial_soln = Bool(True)\n",
    "    \n",
    "    def __init__(self, X, Y, l_theory, l_min, l_1se, sigma_reid):\n",
    "\n",
    "        randomized_lasso.__init__(self, X, Y, l_theory, l_min, l_1se, sigma_reid)\n",
    "        n, p = X.shape\n",
    "        self.lagrange = l_1se * np.ones(X.shape[1])\n",
    "        self.dispersion = np.linalg.norm(Y - X.dot(np.linalg.pinv(X).dot(Y))) ** 2 / (n - p)\n",
    "           \n",
    "    @property\n",
    "    def method_instance(self):\n",
    "        if not hasattr(self, \"_method_instance\"):\n",
    "            n, p = self.X.shape\n",
    "            sigma_ = np.sqrt(self.dispersion)\n",
    "\n",
    "            self._method_instance = rand_lasso.gaussian(self.X,\n",
    "                                                        self.Y,\n",
    "                                                        self.lagrange * n,\n",
    "                                                        randomizer_scale=(\n",
    "                                                        np.sqrt(n) * sigma_ * self.randomizer_scale))\n",
    "        return self._method_instance\n",
    "    \n",
    "    def point_estimator(self):\n",
    "        active, soln = randomized_lasso.point_estimator(self)\n",
    "        if self.use_initial_soln:\n",
    "            soln = self.method_instance.initial_soln\n",
    "        return active, soln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of selective MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLE(Randomized):\n",
    "    method_name = Unicode(\"MLE\")\n",
    "    use_MLE = Bool(True)\n",
    "    use_initial_soln = Bool(False)\n",
    "    model_target = Unicode('full')\n",
    "    \n",
    "    def __init__(self, X, Y, l_theory, l_min, l_1se, sigma_reid):\n",
    "\n",
    "        randomized_lasso.__init__(self, X, Y, l_theory, l_min, l_1se, sigma_reid)\n",
    "        n, p = X.shape\n",
    "        self.lagrange = l_1se * np.ones(X.shape[1])\n",
    "        self.dispersion = np.linalg.norm(Y - X.dot(np.linalg.pinv(X).dot(Y))) ** 2 / (n - p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a simulation collecting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  \n",
    "methods = [Lee, Naive, MLE, Randomized, ROSI]\n",
    "for method in methods:\n",
    "    method.setup(instance.feature_cov, instance)\n",
    "method_params, class_names, method_names = get_method_params(methods)\n",
    "\n",
    "palette = {'MLE': 'blue',\n",
    "           'Naive': 'red',\n",
    "           'Nonrandom': 'orange',\n",
    "           'Randomized': 'purple',\n",
    "           'Full (Nonrandom)': 'green'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 3 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2d8dfa9b7c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m                                           \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                           \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam_1se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                           None)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult_df\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/psnigdha/compare-selection/statistics.pyc\u001b[0m in \u001b[0;36minterval_statistic\u001b[0;34m(method, instance, X, Y, beta, l_theory, l_min, l_1se, sigma_reid, M)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mactive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_intervals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 3 values to unpack"
     ]
    }
   ],
   "source": [
    "nsim = 10\n",
    "snrs = [0.15, 0.21, 0.26, 0.31, 0.42, 0.71, 1.22, 2.07, 3.52]\n",
    "outfile = 'full_target_results.csv'\n",
    "try:\n",
    "    previous = pd.read_csv(outfile)\n",
    "except:\n",
    "    previous = None\n",
    "results = []\n",
    "for i, snr in product(range(nsim),\n",
    "                      snrs):                                                                            \n",
    "\n",
    "    instance.snr = snr                                                                                             \n",
    "    X, Y, beta = instance.generate()                                                             \n",
    "                                                                                                 \n",
    "    # make a hash representing same data                                                         \n",
    "                                                                                                 \n",
    "    instance_hash = hashlib.md5()                                                                \n",
    "    instance_hash.update(X.tobytes())                                                            \n",
    "    instance_hash.update(Y.tobytes())                                                            \n",
    "    instance_hash.update(beta.tobytes())                                                         \n",
    "    instance_id = instance_hash.hexdigest()                                                      \n",
    "\n",
    "    (glm_LASSO_theory,\n",
    "     glm_LASSO_1se,\n",
    "     glm_LASSO_min,\n",
    "     lam_theory,\n",
    "     lam_1se,\n",
    "     lam_min) = glmnet_setup(X,\n",
    "                             Y,\n",
    "                             full_dispersion=True)\n",
    "\n",
    "    for method, method_name, class_name, idx in zip(methods,                                     \n",
    "                                                    method_names,                                \n",
    "                                                    class_names,                                 \n",
    "                                                    range(len(methods))):                        \n",
    "        \n",
    "        M, result_df = interval_statistic(method,\n",
    "                                          instance,\n",
    "                                          X.copy(),\n",
    "                                          Y.copy(),\n",
    "                                          beta.copy(),\n",
    "                                          copy(lam_theory),\n",
    "                                          copy(lam_min),\n",
    "                                          copy(lam_1se),\n",
    "                                          None)\n",
    "        \n",
    "        if result_df is not None:\n",
    "            \n",
    "            result_df['instance_id'] = copy(instance_id)\n",
    "            result_df['method_param'] = str(method_params.loc[idx])\n",
    "            result_df['model_target'] = M.model_target\n",
    "            result_df['method_name'] = method_name\n",
    "            result_df['class_name'] = class_name\n",
    "            \n",
    "            _, estimator_df = estimator_statistic(method,\n",
    "                                                  instance,\n",
    "                                                  X.copy(),\n",
    "                                                  Y.copy(),\n",
    "                                                  beta.copy(),\n",
    "                                                  copy(lam_theory),\n",
    "                                                  copy(lam_min),\n",
    "                                                  copy(lam_1se),\n",
    "                                                  None,\n",
    "                                                  M=M)\n",
    "            for p in instance.params.columns:\n",
    "                result_df[p] = instance.params[p][0]\n",
    "            result_df['confidence'] = M.confidence\n",
    "\n",
    "            for col in estimator_df.columns:\n",
    "                if col not in result_df.columns:\n",
    "                    result_df.insert(1, col, estimator_df[col][0] * np.ones(result_df.shape[0]))\n",
    "            results.append(result_df)\n",
    "        \n",
    "        all_results = pd.concat(results)\n",
    "        if previous is not None:\n",
    "            final_results = pd.concat([all_results, previous])\n",
    "        else:\n",
    "            final_results = all_results\n",
    "        final_results.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if previous is not None:\n",
    "    final_results = pd.concat([all_results, previous])\n",
    "else:\n",
    "    final_results = all_results\n",
    "final_results.to_csv(outfile, index=False)\n",
    "np.unique(final_results['instance_id']).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Discovery Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdp_results = []\n",
    "for key, df in all_results.groupby(['instance_id', 'method_name', 'snr']):\n",
    "    fdp_results.append(list(key[1:]) + [df['fdp'].mean()])\n",
    "fdp_results = pd.DataFrame(fdp_results, columns=['method_name', 'snr', 'FDP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.pointplot(x='snr',\n",
    "              y='FDP',\n",
    "              hue='method_name',\n",
    "              data=fdp_results,\n",
    "              palette=palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "risk_results = []\n",
    "risk_names = sorted([n for n in all_results.columns if 'Risk' in n])\n",
    "for key, df in all_results.groupby(['instance_id', 'method_name', 'snr']):\n",
    "    risk_results.append(list(key[1:]) + [df[n].mean() for n in risk_names])\n",
    "risk_results = pd.DataFrame(risk_results, columns=['method_name', 'snr'] + risk_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.pointplot(x='snr',\n",
    "              y='Full Risk',\n",
    "              hue='method_name',\n",
    "              data=risk_results,\n",
    "              palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.pointplot(x='snr',\n",
    "              y='Partial Relative Risk',\n",
    "              hue='method_name',\n",
    "              data=risk_results,\n",
    "              palette=palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interval_results = []\n",
    "for key, df in all_results.groupby(['instance_id', 'method_name', 'snr']):\n",
    "    if key[1] != 'Randomized':\n",
    "        covered = ((df['lower_confidence'] <= df['target']) & \n",
    "                   (df['upper_confidence'] >= df['target']))\n",
    "        length = df['upper_confidence'] - df['lower_confidence']\n",
    "        interval_results.append(list(key[1:]) + [np.mean(covered), np.median(length)])\n",
    "interval_results = pd.DataFrame(interval_results, columns=['method_name', 'snr'] + ['Coverage', 'Length'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x='snr',\n",
    "                 y='Coverage',\n",
    "                 hue='method_name',\n",
    "                 data=interval_results,\n",
    "                 palette=palette)\n",
    "xlim = ax.get_xlim()\n",
    "ax.plot(xlim, [all_results['confidence'].mean()]*2, 'k--')\n",
    "ax.set_xlim(xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='snr',\n",
    "            y='Length',\n",
    "            hue='method_name',\n",
    "            data=interval_results,\n",
    "            palette=palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_level = 0.1\n",
    "power_results = []\n",
    "for key, df in all_results.groupby(['instance_id', 'method_name', 'snr']):\n",
    "    alt_df = df[lambda df: df['target'] != 0]\n",
    "    power_results.append(list(key[1:]) + [np.mean(alt_df['pvalue'] < test_level)])\n",
    "power_results = pd.DataFrame(power_results, columns=['method_name', 'snr'] + ['Selective Power'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x='snr',\n",
    "                 y='Selective Power',\n",
    "                 hue='method_name',\n",
    "                 data=power_results,\n",
    "                 palette=palette)\n",
    "ax.set_ylim([0,1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power when selecting on `full_target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_level = 0.1\n",
    "power_results = []\n",
    "for key, df in all_results.groupby(['instance_id', 'method_name', 'snr']):\n",
    "    alt_df = df[lambda df: df['full_target'] != 0]\n",
    "    power_results.append(list(key[1:]) + [np.mean(alt_df['pvalue'] < test_level)])\n",
    "power_results = pd.DataFrame(power_results, columns=['method_name', 'snr'] + ['Selective Power'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x='snr',\n",
    "                 y='Selective Power',\n",
    "                 hue='method_name',\n",
    "                 data=power_results,\n",
    "                 palette=palette)\n",
    "ax.set_ylim([0, 1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selective Type I Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_results = []\n",
    "for key, df in all_results.groupby(['instance_id', 'method_name', 'snr']):\n",
    "    null_df = df[lambda df: df['full_target'] == 0]\n",
    "    size_results.append(list(key[1:]) + [np.nanmean(null_df['pvalue'] < test_level)])\n",
    "size_results = pd.DataFrame(size_results, columns=['method_name', 'snr'] + ['Selective Type I Error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x='snr',\n",
    "                 y='Selective Type I Error',\n",
    "                 hue='method_name',\n",
    "                 data=size_results,\n",
    "                 palette=palette)\n",
    "ax.set_ylim([0, 1.1])\n",
    "xlim = ax.get_xlim()\n",
    "ax.plot(xlim, [test_level]*2, 'k--')\n",
    "ax.set_xlim(xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
